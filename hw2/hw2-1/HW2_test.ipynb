{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 24 14:31:18 2018\n",
    "\n",
    "@author: jimmy\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 19 14:51:07 2018\n",
    "\n",
    "@author: jeffchen\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import json\n",
    "\n",
    "###split a sentence \n",
    "def sent2words(sent):\n",
    "    res_para = [j.split(' ') for j in (chr(ord(sent[0])+32) + sent[1:-1]).split(',')]\n",
    "    res_tok = res_para.pop(0)\n",
    "    while len(res_para) != 0:\n",
    "        res_tok.extend([','] + res_para.pop(0)[1:])\n",
    "    #res_tok += ['.']\n",
    "    for j in range(len(res_tok)):\n",
    "        if res_tok[j][-2:] == \"'s\" and res_tok[j] != \"'s\":\n",
    "            res_tok[j] = res_tok[j][:-2]\n",
    "            res_tok.insert(j+1,\"'s\")\n",
    "    return res_tok\n",
    "\n",
    "def generate_word_dict(directory = \"./MLDS_hw2_1_data/\"):\n",
    "    print(\"Loading Data\")\n",
    "    ###Load data\n",
    "    data_direc = directory\n",
    "    # Training part\n",
    "    train_labels, train_feat_dict = [], {}\n",
    "    with open(data_direc + \"training_label.json\", \"r\") as f_train:\n",
    "        train_labels = json.loads(f_train.read())\n",
    "        for i in train_labels:\n",
    "            train_feat_dict[ i['id'] ] = np.load(data_direc + 'training_data/feat/' + i['id'] + '.npy')\n",
    "    \n",
    "    print(len(train_labels))\n",
    "    ###Build word dictionary and pop some words\n",
    "    word_dict = {}\n",
    "    \n",
    "    for i in range(len(train_labels)):\n",
    "        caption_list = train_labels[i]['caption']\n",
    "        for j in range(len(caption_list)):\n",
    "            tokens = sent2words(caption_list[j])\n",
    "            for k in tokens:\n",
    "                if k not in word_dict.keys():\n",
    "                    word_dict[k] = 1\n",
    "                else:\n",
    "                    word_dict[k] += 1\n",
    "            tokens.append('<EOS>')\n",
    "            train_labels[i]['caption'][j] = tokens\n",
    "    to_pop = []\n",
    "    for i in word_dict.keys():\n",
    "        if word_dict[i] < 3:\n",
    "            to_pop.append(i)\n",
    "    for i in to_pop:\n",
    "        word_dict.pop(i)\n",
    "    print(\"Finish count words\")\n",
    "    int_to_dict = {}\n",
    "    for num, key in enumerate(word_dict.keys()):\n",
    "        int_to_dict[num] = key\n",
    "    n_words = len(int_to_dict)\n",
    "    int_to_dict[n_words] = '<UNK>'\n",
    "    int_to_dict[n_words+1] = '<BOS>'\n",
    "    int_to_dict[n_words+2] = '<EOS>'\n",
    "    return int_to_dict\n",
    "\n",
    "def generate_test_dataloader(directory = \"./MLDS_hw2_1_data/\", batch_size = 16):\n",
    "    print(\"Loading Data\")\n",
    "    ###Load data\n",
    "    data_direc = directory\n",
    "      \n",
    "    # Testing part\n",
    "    test_labels, test_feat_dict = [], {}\n",
    "    with open(data_direc + \"testing_label.json\", \"r\") as f_test:\n",
    "        test_labels = json.loads(f_test.read())\n",
    "        for i in test_labels:\n",
    "            test_feat_dict[ i['id'] ] = np.load(data_direc + 'testing_data/feat/' + i['id'] + '.npy')\n",
    "    print(len(test_labels))\n",
    "    ###Build word dictionary and pop some words\n",
    "    \n",
    "    test_x = []\n",
    "    video_id_list = []\n",
    "    for data_num in range(len(test_labels)):\n",
    "        print(\"Process data \",data_num,\" to list\")\n",
    "\n",
    "        video_id = test_labels[data_num]['id']\n",
    "        video_id_list.append(video_id)\n",
    "        test_x.append(test_feat_dict[video_id]) \n",
    " \n",
    "    test_x = np.array(test_x)\n",
    "    \n",
    "    print(\"Convert to Tensor\")\n",
    "    tensor_test_x = torch.Tensor(test_x)\n",
    "    #dataset = torch.utils.data.TensorDataset((tensor_test_x))\n",
    "    #dataloader = torch.utils.data.DataLoader(dataset = dataset, batch_size = batch_size, shuffle=False)\n",
    "    return tensor_test_x, video_id_list\n",
    "\n",
    "def prediction(model_dir, input_x, id_list, int_to_word):\n",
    "    file = open(\"TEST.txt\",'w')\n",
    "    model = torch.load(model_dir).cuda()\n",
    "    for i in range(len(input_x)):\n",
    "        input_data = input_x[i].reshape(80, 1, 4096).cuda()\n",
    "        sentence = \"\"\n",
    "        ans = model.test(input_data, 44)\n",
    "        #print(ans[0])\n",
    "        for j in range(len(ans)):\n",
    "            one_word = int_to_word[torch.argmax(ans[j]).item()]\n",
    "            if(one_word == '<EOS>'):\n",
    "                print(\"Have EOS\")\n",
    "                break\n",
    "            sentence += \" \"+one_word\n",
    "        file.write(id_list[i]+','+sentence+'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "1450\n",
      "Finish count words\n"
     ]
    }
   ],
   "source": [
    "int_to_word = generate_word_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<EOS>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word[2889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "100\n",
      "Process data  0  to list\n",
      "Process data  1  to list\n",
      "Process data  2  to list\n",
      "Process data  3  to list\n",
      "Process data  4  to list\n",
      "Process data  5  to list\n",
      "Process data  6  to list\n",
      "Process data  7  to list\n",
      "Process data  8  to list\n",
      "Process data  9  to list\n",
      "Process data  10  to list\n",
      "Process data  11  to list\n",
      "Process data  12  to list\n",
      "Process data  13  to list\n",
      "Process data  14  to list\n",
      "Process data  15  to list\n",
      "Process data  16  to list\n",
      "Process data  17  to list\n",
      "Process data  18  to list\n",
      "Process data  19  to list\n",
      "Process data  20  to list\n",
      "Process data  21  to list\n",
      "Process data  22  to list\n",
      "Process data  23  to list\n",
      "Process data  24  to list\n",
      "Process data  25  to list\n",
      "Process data  26  to list\n",
      "Process data  27  to list\n",
      "Process data  28  to list\n",
      "Process data  29  to list\n",
      "Process data  30  to list\n",
      "Process data  31  to list\n",
      "Process data  32  to list\n",
      "Process data  33  to list\n",
      "Process data  34  to list\n",
      "Process data  35  to list\n",
      "Process data  36  to list\n",
      "Process data  37  to list\n",
      "Process data  38  to list\n",
      "Process data  39  to list\n",
      "Process data  40  to list\n",
      "Process data  41  to list\n",
      "Process data  42  to list\n",
      "Process data  43  to list\n",
      "Process data  44  to list\n",
      "Process data  45  to list\n",
      "Process data  46  to list\n",
      "Process data  47  to list\n",
      "Process data  48  to list\n",
      "Process data  49  to list\n",
      "Process data  50  to list\n",
      "Process data  51  to list\n",
      "Process data  52  to list\n",
      "Process data  53  to list\n",
      "Process data  54  to list\n",
      "Process data  55  to list\n",
      "Process data  56  to list\n",
      "Process data  57  to list\n",
      "Process data  58  to list\n",
      "Process data  59  to list\n",
      "Process data  60  to list\n",
      "Process data  61  to list\n",
      "Process data  62  to list\n",
      "Process data  63  to list\n",
      "Process data  64  to list\n",
      "Process data  65  to list\n",
      "Process data  66  to list\n",
      "Process data  67  to list\n",
      "Process data  68  to list\n",
      "Process data  69  to list\n",
      "Process data  70  to list\n",
      "Process data  71  to list\n",
      "Process data  72  to list\n",
      "Process data  73  to list\n",
      "Process data  74  to list\n",
      "Process data  75  to list\n",
      "Process data  76  to list\n",
      "Process data  77  to list\n",
      "Process data  78  to list\n",
      "Process data  79  to list\n",
      "Process data  80  to list\n",
      "Process data  81  to list\n",
      "Process data  82  to list\n",
      "Process data  83  to list\n",
      "Process data  84  to list\n",
      "Process data  85  to list\n",
      "Process data  86  to list\n",
      "Process data  87  to list\n",
      "Process data  88  to list\n",
      "Process data  89  to list\n",
      "Process data  90  to list\n",
      "Process data  91  to list\n",
      "Process data  92  to list\n",
      "Process data  93  to list\n",
      "Process data  94  to list\n",
      "Process data  95  to list\n",
      "Process data  96  to list\n",
      "Process data  97  to list\n",
      "Process data  98  to list\n",
      "Process data  99  to list\n",
      "Convert to Tensor\n"
     ]
    }
   ],
   "source": [
    "test_data, id_list = generate_test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'S2VT.S2VT' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'S2VT.Attention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n",
      "Encoding\n",
      "Decoding\n",
      "Have EOS\n"
     ]
    }
   ],
   "source": [
    "import S2VT\n",
    "\n",
    "model = torch.load('./s2vt_1025_2_old.pkl')\n",
    "model.batch_size = 1\n",
    "model.encoder_h = torch.zeros((1, 1, 256),\n",
    "                                      dtype = torch.float32).cuda()\n",
    "model.encoder_c = torch.zeros((1, 1, 256),\n",
    "                                      dtype = torch.float32).cuda()\n",
    "model.decoder_h = torch.zeros((1, 1, 256),\n",
    "                                      dtype = torch.float32).cuda()\n",
    "model.decoder_c = torch.zeros((1, 1, 256),\n",
    "                                      dtype = torch.float32).cuda()\n",
    "torch.save(model, './s2vt_1025_2_old_MODEL.pkl')\n",
    "\n",
    "prediction('./s2vt_1025_2_old_MODEL.pkl', test_data, id_list, int_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2367, 1.1624, 0.0000,  ..., 0.0000, 0.0000, 0.4624],\n",
       "        [0.0000, 1.2430, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0580, 0.0000,  ..., 0.0000, 0.0000, 0.1048],\n",
       "        ...,\n",
       "        [1.6902, 2.8036, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.7786, 2.6784, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.9601, 2.7707, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
